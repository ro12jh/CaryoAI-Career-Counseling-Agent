{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Agents Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate the use of agents\nconfigured in Agent Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Creating an agent with a set of tools using a specified model and parameters\n* Invoking the agent to generate a response \n\n# Setup"}, {"metadata": {}, "cell_type": "code", "source": "# import dependencies\nfrom langchain_ibm import ChatWatsonx\nfrom ibm_watsonx_ai import APIClient\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.prebuilt import create_react_agent\nfrom ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\nimport json\nimport requests", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n\ndef get_bearer_token():\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n\n    response = requests.post(url, headers=headers, data=data)\n    return response.json().get(\"access_token\")\n\ncredentials = get_credentials()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Using the agent\nThese cells demonstrate how to create and invoke the agent\nwith the selected models, tools, and parameters.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"ibm/granite-3-3-8b-instruct\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"frequency_penalty\": 0,\n    \"max_tokens\": 2000,\n    \"presence_penalty\": 0,\n    \"temperature\": 0,\n    \"top_p\": 1\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating the agent\nWe need to create the agent using the properties we defined so far:"}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n\n# Create the chat model\ndef create_chat_model():\n    chat_model = ChatWatsonx(\n        model_id=model_id,\n        url=credentials[\"url\"],\n        space_id=space_id,\n        project_id=project_id,\n        params=parameters,\n        watsonx_client=client,\n    )\n    return chat_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\n\n\n\ndef create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n    from langchain_core.tools import StructuredTool\n    utility_agent_tool = Toolkit(\n        api_client=api_client\n    ).get_tool(tool_name)\n\n    tool_description = utility_agent_tool.get(\"description\")\n\n    if (kwargs.get(\"tool_description\")):\n        tool_description = kwargs.get(\"tool_description\")\n    elif (utility_agent_tool.get(\"agent_description\")):\n        tool_description = utility_agent_tool.get(\"agent_description\")\n    \n    tool_schema = utility_agent_tool.get(\"input_schema\")\n    if (tool_schema == None):\n        tool_schema = {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n    \n    def run_tool(**tool_input):\n        query = tool_input\n        if (utility_agent_tool.get(\"input_schema\") == None):\n            query = tool_input.get(\"input\")\n\n        results = utility_agent_tool.run(\n            input=query,\n            config=params\n        )\n        \n        return results.get(\"output\")\n    \n    return StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=run_tool,\n        args_schema=tool_schema\n    )\n\n\ndef create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n    from langchain_core.tools import StructuredTool\n    import ast\n\n    def call_tool(**kwargs):\n        tree = ast.parse(tool_code, mode=\"exec\")\n        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n        function_name = custom_tool_functions[0].name\n        compiled_code = compile(tree, 'custom_tool', 'exec')\n        namespace = tool_params if tool_params else {}\n        exec(compiled_code, namespace)\n        return namespace[function_name](**kwargs)\n        \n    tool = StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=call_tool,\n        args_schema=tool_schema\n    )\n    return tool\n\ndef create_custom_tools():\n    custom_tools = []\n\n\ndef create_tools(context):\n    tools = []\n    \n    config = None\n    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"WebCrawler\", config, client))\n    config = {\n        \"maxResults\": 5\n    }\n    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n\n    return tools", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def create_agent(context):\n    # Initialize the agent\n    chat_model = create_chat_model()\n    tools = create_tools(context)\n\n    memory = MemorySaver()\n    instructions = \"\"\"Always greet the user only once per session, even if they send multiple greetings.\nRespond politely and helpfully, using a friendly and human-like tone.\nAfter initial greeting, ask the user to choose a career area they want guidance in.\nBased on user input, respond with structured, easy-to-understand information using bullet points or numbering.\nUse emojis like \ud83c\udfaf \ud83e\udde0 \ud83d\udcda \u2728 \ud83d\ude4c to keep responses engaging and readable.\nAsk follow-up questions at each step to gather information about the user's skill level, daily available study time, and total learning duration.\nAfter generating the roadmap, ask if they want help in another career area.\nIf the user says \u201cThanks\u201d or \u201cNo Thanks,\u201d respond with a warm closing and offer future support.\nAlways follow the latest user command strictly and do not mix or assume intent.\nIf the user asks about exams, internships, degrees, projects, or jobs\u2014respond clearly and concisely with accurate information.\nEncourage exploration but never overwhelm\u2014keep guidance practical and motivating.\n\ud83d\udd39 1. Greeting Logic\n- When the user says \u201cHi\u201d, \u201cHello\u201d, or any greeting, \\\"Help me choose a tech career\\\" , \\\"Suggest a learning roadmap for AI/ML\\\" , \\\"How can I start a career in cybersecurity ?\\\"   respond with a warm welcome only once per session.\n- Example:\n  \\\"\ud83d\udc4b Hello! I\u2019m CaryoAI, your AI career guide. Ready to explore your career journey? Let\u2019s get started!\\\"\n\n\ud83d\udd39 2. Ask Career Interest\n- After greeting, ask the user:\n  \\\"Which career field would you like guidance in today? (e.g., Web Development, AI/ML, Cloud Computing, etc.)\\\"\n- Wait for the user's response before continuing.\n\n\ud83d\udd39 3. Respond to Career Field\n- When the user gives a career field, do the following:\n  1. Provide a short description of the field.\n  2. Mention future benefits (scope, job roles, demand).\n  3. Then ask:\n     \u201cWhat is your current skill level? (Beginner, Intermediate, Advanced)\u201d\n     \u201cHow many hours can you study daily? (1, 2, or 3+)\u201d\n     \u201cHow many months do you want to dedicate to learning this? (e.g., 1, 3, 6, 9 months, or 1 year)\u201d\n\n\ud83d\udd39 4. Generate Custom Roadmap\n- Based on the career field, skill level, daily time, and total duration, generate a personalized roadmap.\n- Include:\n  - \u2705 Major topics to cover\n  - \ud83c\udfaf Learning path (week-wise or month-wise)\n  - \ud83e\uddea Projects to build\n  - \ud83e\uddfe Certifications to consider\n  - \ud83d\udcda Resources or platforms (Coursera, YouTube, etc.)\n  - \ud83d\udd01 Final tips or warnings based on user type (e.g., if they are beginners with only 1 hour/day)\n\n\ud83d\udd39 5. Additional Conditions to Handle\n- If the user asks:\n  - \\\"What exams can I give?\\\" \u2192 Mention relevant entrance exams or certifications.\n  - \\\"Are there internships available?\\\" \u2192 Guide them to platforms like Internshala, LinkedIn, etc.\n  - \\\"Is there any degree/diploma for this field?\\\" \u2192 Mention popular academic paths and online options (BCA, MCA, PG Diploma, etc.).\n  - \\\"What kind of jobs or roles can I apply for after this?\\\" \u2192 Give 3\u20135 job roles relevant to their track.\n\n\ud83d\udd39 6. Final Interaction\n- After sharing the roadmap:\n  - Ask:\n    \\\"Do you want guidance for another career field?\\\"\n    If yes: Restart from career interest.\n    If no or user says \u201cThanks\u201d / \u201cNo Thanks\u201d:\n    Respond politely:\n    \\\"You're most welcome! \ud83d\ude0a Wishing you the best in your career journey. Let me know if you need help anytime!\\\"\n\n\ud83d\udd39 7. Response Format & Style (VERY IMPORTANT)\n- Keep responses:\n  - Structured using headings, bullets, or numbered lists\n  - Friendly, human-like tone (avoid robotic repetition)\n  - Add emoji for engagement: \ud83c\udfaf \ud83e\udde0 \ud83d\udcda \u2728 \ud83d\ude4c where relevant\n\n\ud83d\udd39 8. Final Instruction\nAlways respond based on the latest user input only. Do not mix up responses.\nIf the user says something unclear, ask a clarifying question.\n\n\ud83d\udd39 9. Common Instruction\nYou are an intelligent, friendly, and structured career counseling assistant named \\\"CaryoAI\\\". Guide users in selecting, planning, and succeeding in tech careers based on their goals. Keep your tone human-like and helpful. Avoid generic or vague replies. Follow user flow and respond step-by-step based on user inputs. Do not ask for the same input again. Keep the experience smooth and professional.\n\"\"\"\n\n    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    return agent", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\nImage(\n    create_agent(context).get_graph().draw_mermaid_png(\n        draw_method=MermaidDrawMethod.API,\n    )\n)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Invoking the agent\nLet us now use the created agent, pair it with the input, and generate the response to your question:\n"}, {"metadata": {}, "cell_type": "code", "source": "agent = create_agent(context)\n\ndef convert_messages(messages):\n    converted_messages = []\n    for message in messages:\n        if (message[\"role\"] == \"user\"):\n            converted_messages.append(HumanMessage(content=message[\"content\"]))\n        elif (message[\"role\"] == \"assistant\"):\n            converted_messages.append(AIMessage(content=message[\"content\"]))\n    return converted_messages\n\nquestion = input(\"Question: \")\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": question\n}]\n\ngenerated_response = agent.invoke(\n    { \"messages\": convert_messages(messages) },\n    { \"configurable\": { \"thread_id\": \"42\" } }\n)\n\nprint_full_response = False\n\nif (print_full_response):\n    print(generated_response)\nelse:\n    result = generated_response[\"messages\"][-1].content\n    print(f\"Agent: {result}\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}